<?xml version="1.0" encoding="UTF-8"?>
<!doctype html>
<html>
	<head>
		<style type="text/css">
			h2 {
				font: -apple-system-headline;
			}
			body {
				font: -apple-system-body;
				zoom: 1.2;
			}
			img {
				width: auto;
				height : auto;
				max-height: 100%;
				max-width: 100%;
			}
		</style>
	</head>
	<body>
		<h2>CaffeToCoreML</h2>
		There are a lot of tutorials/ open source projects on how to use Vision and CoreML frameworks for Object Detection in real world using iOS apps using .mlmodels given by Apple. But seldom in reality, do we get a .mlmodel available suiting our use case.  Here, I took up a Caffe model for the Oxford 102 flower dataset, which was converted to CoreML model using coremltools python package.<p><img alt="image of this control" src="https://s3.amazonaws.com/cocoacontrols_production/uploads/control_image/image/13012/Screen_Shot_2017-12-13_at_5.40.17_PM_copy.jpg"></p><img src="http://feeds.feedburner.com/~r/CocoaControls/~4/swrs4F28RAA" height="1" width="1" alt="">
	</body>
</html>
